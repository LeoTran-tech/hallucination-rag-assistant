{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d200c481",
   "metadata": {},
   "source": [
    "## This notebooks contains the code to build the MVP of our RAG assistant. It includes:\n",
    "- A search function that queries the ChromaDB collection for relevant chunks based on a question\n",
    "- A function to build a context string from the search hits, which will be used as input to the LLM\n",
    "- A function to call the local Ollama LLM with a prompt and get an answer\n",
    "The final part of the notebook calls the answer function with a sample question and prints the answer.\n",
    "We also have a compare_papers function that takes a question and a list of paper IDs, retrieves relevant chunks\n",
    "for each paper, builds a context, and prompts the LLM to compare the papers with respect to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3500d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install pymupdf pandas tqdm tiktoken\n",
    "# !pip -q install --upgrade openai\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8774c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda_envs\\hallucination-rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 201.03it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-base-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use the BGE model from BAAI, which is a strong open-source embedding model \n",
    "# that converts text into vector embeddings. These embeddings can be used for\n",
    "# tasks like semantic search, etc. We will use this model later to convert\n",
    "# our text chunks into embeddings\n",
    "embed_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model = SentenceTransformer(embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db399fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DIR = DATA_DIR / \"chroma_db\"\n",
    "client = chromadb.PersistentClient(path=str(CHROMA_DIR), settings=Settings(anonymized_telemetry=False))\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"hallucination_faithfulness_chunks\",\n",
    "    metadata={\"embedding_model\": embed_model_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149ba2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=5, where=None, *, return_text_preview_chars=700):\n",
    "    q_emb = model.encode([query], normalize_embeddings=True).tolist()\n",
    "\n",
    "    res = collection.query(\n",
    "        query_embeddings=q_emb,\n",
    "        n_results=k,\n",
    "        where=where\n",
    "    )\n",
    "\n",
    "    hits = []\n",
    "    n = min(k, len(res[\"ids\"][0]))\n",
    "\n",
    "    for i in range(n):\n",
    "        meta = res[\"metadatas\"][0][i] or {}\n",
    "        doc  = res[\"documents\"][0][i] or \"\"\n",
    "        dist = res[\"distances\"][0][i]\n",
    "\n",
    "        hits.append({\n",
    "            \"rank\": i + 1,\n",
    "            \"distance\": float(dist),\n",
    "            \"paper_id\": meta.get(\"paper_id\"),\n",
    "            \"year\": meta.get(\"year\"),\n",
    "            \"page\": meta.get(\"page\"),\n",
    "            \"title\": meta.get(\"title\", \"\"),\n",
    "            \"source_file\": meta.get(\"source_file\", \"\"),\n",
    "            \"text\": doc,\n",
    "            \"text_preview\": doc[:return_text_preview_chars].strip()\n",
    "        })\n",
    "\n",
    "    return hits\n",
    "\n",
    "def build_context(hits, max_chars=6000):\n",
    "    blocks = []\n",
    "    total = 0\n",
    "    for h in hits:\n",
    "        block = f\"[{h['paper_id']} p.{h['page']}] {h['title']}\\n{h['text'].strip()}\\n\"\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "        blocks.append(block)\n",
    "        total += len(block)\n",
    "    return \"\\n\\n\".join(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"key.txt\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e14e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def call_llm(prompt: str, model: str = GPT_MODEL, temperature: float = 0.2, max_tokens: int = 700) -> str:\n",
    "    \"\"\"\n",
    "    Call gpt-4o-mini model.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.output_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268cf50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Verification layer\n",
    "# ==============================\n",
    "\n",
    "def verify_answer_support(answer_text, hits):\n",
    "    cited = set()\n",
    "    for h in hits:\n",
    "        pid = h.get(\"paper_id\")\n",
    "        if pid and pid in answer_text:\n",
    "            cited.add(pid)\n",
    "\n",
    "    return {\n",
    "        \"cited_papers\": list(cited),\n",
    "        \"num_cited\": len(cited),\n",
    "        \"num_hits\": len(hits)\n",
    "    }\n",
    "\n",
    "\n",
    "def self_check(question, answer, context):\n",
    "    prompt = f\"\"\"\n",
    "Given the QUESTION and CONTEXT,\n",
    "does the ANSWER strictly rely only on the CONTEXT?\n",
    "\n",
    "If any claim is unsupported, list it.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "ANSWER:\n",
    "{answer}\n",
    "\"\"\"\n",
    "    return call_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f36d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_citations(hits, top_n=5):\n",
    "    # make citation [paper_id p.page] file\n",
    "    cits = []\n",
    "    for h in hits[:top_n]:\n",
    "        cits.append({\n",
    "            \"paper_id\": h.get(\"paper_id\"),\n",
    "            \"page\": h.get(\"page\"),\n",
    "            \"title\": h.get(\"title\"),\n",
    "            \"source_file\": h.get(\"source_file\"),\n",
    "            \"distance\": h.get(\"distance\"),\n",
    "        })\n",
    "    return cits\n",
    "\n",
    "\n",
    "def answer(question, *, k=8, where=None, max_ctx_chars=8000):\n",
    "    hits = search(question, k=k, where=where)\n",
    "    context = build_context(hits, max_chars=max_ctx_chars)  \n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a research assistant specialized in LLM hallucination & faithfulness.\n",
    "Answer the QUESTION using ONLY the CONTEXT.\n",
    "If the context is insufficient, say \"I don't know from the provided papers.\"\n",
    "\n",
    "You must cite sources inline like: [paper_id p.page]\n",
    "At the end, output a bullet list \"Sources\" with unique citations.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    llm_text = call_llm(prompt)\n",
    "\n",
    "    verification = verify_answer_support(llm_text, hits)\n",
    "    self_eval = self_check(question, llm_text, context)\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": llm_text,\n",
    "        \"hits\": hits,\n",
    "        \"citations\": make_citations(hits, top_n=5),\n",
    "        \"verification\": verification,\n",
    "        \"self_evaluation\": self_eval,\n",
    "        \"context_chars\": len(context),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2f38d",
   "metadata": {},
   "source": [
    "## The same query is used twice to compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421db4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers define faithfulness as a multi-party property where a faithful explanation allows a listener model to reach the same conclusion as a speaker model, without access to the speaker's final answer. Faithfulness is framed in terms of reasoning executability, meaning a reasoning chain is considered faithful if it can be executed by a listener to recover the same conclusion. The degree of faithfulness is quantified by whether the listener reaches the same answer as the speaker, indicating a successful execution of the reasoning process [2602.16154v1 p.1][2602.16154v1 p.9].\n",
      "\n",
      "Sources:\n",
      "- [2602.16154v1 p.1]\n",
      "- [2602.16154v1 p.9]\n",
      "{'cited_papers': ['2602.16154v1'], 'num_cited': 1, 'num_hits': 10}\n",
      "The answer provided does rely strictly on the context given, as it summarizes the definition of faithfulness as described in the context. The definition includes key elements such as the multi-party nature of faithfulness, the role of reasoning executability, and how faithfulness is quantified.\n",
      "\n",
      "### Unsupported Claims:\n",
      "There are no unsupported claims in the answer. All points made are directly supported by the context provided. The answer accurately reflects the definitions and concepts discussed in the context regarding faithfulness in reasoning models.\n"
     ]
    }
   ],
   "source": [
    "res = answer(\"How do papers define faithfulness or groundedness?\", k=10)\n",
    "print(res[\"answer\"])\n",
    "print(res[\"verification\"])\n",
    "print(res[\"self_evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f24bbb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The papers define faithfulness as a multi-party property where a faithful explanation allows a listener model to reach the same conclusion as the speaker model without access to the speaker's final answer. Faithfulness is framed as a question of reasoning executability, meaning a reasoning chain is considered faithful if it can be executed by a listener to recover the same conclusion based on a provided reasoning prefix. This is distinct from correctness, which is objectively defined. The proposed method, Reasoning Execution by Multiple Listeners (REMUL), emphasizes training models for both faithfulness and correctness simultaneously, indicating that faithfulness is critical for monitorability, verifiability, and trust in models [2602.16154v1 p.1][2602.16154v1 p.9].\n",
      "\n",
      "- **Sources**\n",
      "  - [2602.16154v1 p.1]\n",
      "  - [2602.16154v1 p.9]\n",
      "{'cited_papers': ['2602.16154v1'], 'num_cited': 1, 'num_hits': 10}\n",
      "The answer provided does rely strictly on the context given, as it accurately summarizes the definition of faithfulness as described in the context. The explanation of faithfulness as a multi-party property, the distinction from correctness, and the framing of faithfulness in terms of reasoning executability are all directly supported by the context.\n",
      "\n",
      "### Unsupported Claims:\n",
      "There are no unsupported claims in the answer; all statements made are substantiated by the provided context.\n"
     ]
    }
   ],
   "source": [
    "res = answer(\"How do papers define faithfulness or groundedness?\", k=10)\n",
    "print(res[\"answer\"])\n",
    "print(res[\"verification\"])\n",
    "print(res[\"self_evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_papers(question, paper_ids, *, k_per_paper=4):\n",
    "    all_hits = []\n",
    "    for pid in paper_ids:\n",
    "        hits = search(question, k=k_per_paper, where={\"paper_id\": pid})\n",
    "        all_hits.extend(hits)\n",
    "\n",
    "    # sort theo distance \n",
    "    all_hits = sorted(all_hits, key=lambda x: x[\"distance\"])\n",
    "    context = build_context(all_hits, max_chars=9000)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Compare the papers with respect to the QUESTION.\n",
    "Use ONLY the CONTEXT. Cite inline [paper_id p.page].\n",
    "Output:\n",
    "- Summary table (paper_id -> key points)\n",
    "- Agreement / disagreement\n",
    "- Practical takeaway\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    llm_text = call_llm(prompt)\n",
    "    return {\"question\": question, \"paper_ids\": paper_ids, \"answer\": llm_text, \"hits\": all_hits}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58aabf2",
   "metadata": {},
   "source": [
    "## Compare the 2 papers with a question twice to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary Table\n",
      "\n",
      "| Paper ID | Key Points |\n",
      "| --- | --- |\n",
      "| 2602.16154v1 p.3 | - Defines faithfulness as the degree to which a listener model reaches the same answer as the original speaker reasoning model.<br>- Uses multi-listener soft execution for training, where truncated reasoning chains are provided to multiple listeners to compute matching rewards. |\n",
      "| 2602.16154v1 p.6 | - Evaluates faithfulness using AOC metrics across different methods and shows REMUL balances faithfulness and correctness.<br>- Faithfulness-only training improves AOC, while hint-optimized models perform poorly. |\n",
      "| 2602.16154v1 p.1 | - Argues that faithfulness is a multi-party property enabling listeners to reach the same conclusion as speakers without access to answers.<br>- Proposes REMUL for balancing faithfulness and correctness. |\n",
      "\n",
      "### Agreement / Disagreement\n",
      "\n",
      "- **Agreement**: Both papers agree on defining faithfulness in terms of listener models reaching the same conclusions as speaker models.\n",
      "- **Disagreement**: The second paper (2602.16154v1 p.6) provides a more detailed evaluation and comparison of different training methods, showing that REMUL balances both faithfulness and correctness better than other approaches.\n",
      "\n",
      "### Practical Takeaway\n",
      "\n",
      "- **Faithfulness Definition**: Faithfulness should be understood as the ability of listener models to reach the same conclusion as speaker models without access to their answers.\n",
      "- **Training Methodology**: Multi-listener soft execution (REMUL) is effective in balancing faithfulness and correctness, providing a robust approach for training reasoning models. This method ensures that models are not only correct but also faithful to the intended reasoning process.\n",
      "\n",
      "By adopting REMUL or similar methodologies, developers can ensure that AI systems provide both accurate and interpretable outputs, enhancing user trust and understanding.\n"
     ]
    }
   ],
   "source": [
    "cmp_res = compare_papers(\n",
    "    \"How is faithfulness defined and measured?\",\n",
    "    paper_ids=[\"2602.16154v1\", \"2602.14529v1\"]\n",
    ")\n",
    "print(cmp_res[\"answer\"])\n",
    "\n",
    "# 4m55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4869c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary Table\n",
      "\n",
      "| Paper ID | Key Points |\n",
      "| --- | --- |\n",
      "| 2602.16154v1 p.3 | Faithfulness is defined as the degree to which a listener model reaches the same answer as the original speaker reasoning model. The faithfulness reward is computed by comparing the answers of multiple listeners with the original answer. |\n",
      "| 2602.16154v1 p.6 | REMUL trains models for both faithfulness and correctness simultaneously, using truncated CoT answering and adding mistakes to measure faithfulness. Faithfulness-only training improves AOC metrics, while hint-optimized models perform worse on these metrics. |\n",
      "| 2602.16154v1 p.1 | Faithfulness is a multi-party property where the speaker's reasoning must be executable by a listener without access to the answer. REMUL uses soft execution and multiple listeners for training. |\n",
      "\n",
      "### Agreement / Disagreement\n",
      "\n",
      "- **Agreement**: Both papers agree that faithfulness involves ensuring the listener model reaches the same conclusion as the speaker, even when only part of the reasoning chain is provided.\n",
      "- **Disagreement**: The first paper (2602.16154v1 p.3) provides a more detailed definition and computation method for faithfulness, while the second paper (2602.16154v1 p.6) focuses on the metrics used to measure it.\n",
      "\n",
      "### Practical Takeaway\n",
      "\n",
      "- **Definition of Faithfulness**: Faithfulness is crucial in ensuring that AI models provide explanations or reasoning chains that are understandable and executable by other models, even when parts of the chain are truncated.\n",
      "- **Training Methods**: Training methods like REMUL (2602.16154v1 p.3) can balance faithfulness with correctness, while metrics like AOC and hint usage help in measuring these properties effectively.\n",
      "\n",
      "By focusing on both the definition and practical training methods for faithfulness, researchers can ensure that AI models provide clear and executable reasoning chains, enhancing their overall utility and reliability.\n"
     ]
    }
   ],
   "source": [
    "cmp_res = compare_papers(\n",
    "    \"How is faithfulness defined and measured?\",\n",
    "    paper_ids=[\"2602.16154v1\", \"2602.14529v1\"]\n",
    ")\n",
    "print(cmp_res[\"answer\"])\n",
    "\n",
    "# 1m16.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893abc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_stats(hits):\n",
    "    unique_papers = len(set(h['paper_id'] for h in hits))\n",
    "    return {\n",
    "        \"unique_papers\": unique_papers,\n",
    "        \"total_hits\": len(hits),\n",
    "        \"diversity_ratio\": unique_papers / len(hits)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
